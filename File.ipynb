{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a712543-1513-4f98-8c73-51182740db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 02m 54s]\n",
      "val_accuracy: 0.5139999985694885\n",
      "\n",
      "Best val_accuracy So Far: 0.6581000089645386\n",
      "Total elapsed time: 00h 24m 39s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "112               |48                |conv1_units\n",
      "80                |128               |conv2_units\n",
      "112               |128               |dense_units\n",
      "0.3               |0.1               |dropout_rate\n",
      "0.01              |0.001             |learning_rate\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 82ms/step - accuracy: 0.1025 - loss: 2.3632 - val_accuracy: 0.1000 - val_loss: 2.3031\n",
      "Epoch 2/2\n",
      "\u001b[1m 395/1563\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44\u001b[0m 89ms/step - accuracy: 0.0992 - loss: 2.3040"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from keras_tuner import Hyperband  # Install keras-tuner if not installed: pip install keras-tuner\n",
    "\n",
    "# Define the model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layers with tunable hyperparameters\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv1_units', min_value=32, max_value=128, step=16),  # Tunable number of filters\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(32, 32, 3)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('conv2_units', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=32, max_value=128, step=16),  # Tunable dense units\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dropout(\n",
    "        rate=hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)  # Tunable dropout rate\n",
    "    ))\n",
    "    model.add(layers.Dense(10, activation='softmax'))  # Output layer with 10 classes\n",
    "\n",
    "    # Optimizer with tunable learning rate\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])  # Tunable learning rate\n",
    "    )\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # Use from_logits=False for softmax\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_val, y_val) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize the data\n",
    "x_train, x_val = x_train / 255.0, x_val / 255.0\n",
    "\n",
    "# Define the tuner\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # Metric to optimize\n",
    "    max_epochs=10,  # Maximum number of epochs per trial\n",
    "    factor=3,  # Reduction factor for the number of configurations\n",
    "    directory='hyperband_dir',  # Directory to save results\n",
    "    project_name='cifar10_tuning'  # Project name\n",
    ")\n",
    "\n",
    "# Run the search for the best hyperparameters\n",
    "tuner.search(\n",
    "    x_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Display the optimal hyperparameters\n",
    "print(f\"\"\"\n",
    "The optimal number of filters in the first Conv2D layer is {best_hps.get('conv1_units')}.\n",
    "The optimal number of filters in the second Conv2D layer is {best_hps.get('conv2_units')}.\n",
    "The optimal number of units in the dense layer is {best_hps.get('dense_units')}.\n",
    "The optimal dropout rate is {best_hps.get('dropout_rate')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the best hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=20,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(x_val, y_val)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20490f-4e97-49e6-a18a-12ff931ea2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
